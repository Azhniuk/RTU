# -*- coding: utf-8 -*-
"""Waste classification_NEW.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11LWCZ24MjMbDhNO_ccI8X6gElB-GSEN4
"""

import os
import shutil
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.utils import to_categorical

import random

WIDTH=150
HEIGHT=150
IMAGE_SIZE=(WIDTH, HEIGHT)
IMAGE_CHANNELS=3
batch_size = 20

pip install py7zr

from google.colab import drive
drive.mount('/content/drive')

import py7zr

# with ZipFile('../content/drive/MyDrive/GlassMetal.zip', 'r') as zip:
#     zip.extractall()


with py7zr.SevenZipFile('../content/drive/MyDrive/PapPla.7z', mode='r') as z:
     z.extractall()

path =  "/content/PapPla"

train_dir = os.path.join(path, "train")
validation_dir = os.path.join(path, "validation")
model_dir = path
filenames = os.listdir(path)

#delete dirs
shutil.rmtree( train_dir )
shutil.rmtree( validation_dir )

shutil.rmtree( path )

labels = ["plastic", "paper"]
labels.sort()

os.makedirs(train_dir)
os.makedirs(validation_dir)

for label in labels:
  os.makedirs(os.path.join(train_dir, label))
  os.makedirs(os.path.join(validation_dir, label))

df = pd.DataFrame(data=filenames, columns=['file_name'])
total_train, total_validate = 0, 0

df['label'] = df['file_name'].apply(lambda x: "paper" if x[:3]=='car'

                                    else "paper" if x[:3]=='pap'
                                    else "plastic")


for label in df['label'].unique():
    files = df[df['label']==label]['file_name']
    train = np.random.choice(files, size=int(len(files)*0.8))
    test = [_ for _ in files if not (_ in train)]
    print(label, len(files), len(train), len(test))
    total_train += len(train)
    total_validate += len(test)

    for file in train:
      shutil.copyfile(os.path.join(path, file),
                     os.path.join(train_dir, label, file))

    for file in test:
      shutil.copyfile(os.path.join(path, file),
                     os.path.join(validation_dir, label, file))

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (2,2), activation='relu', input_shape=(WIDTH, HEIGHT, IMAGE_CHANNELS)),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(32, (2,2), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.BatchNormalization(),

    tf.keras.layers.Conv2D(64, (2,2), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.1),

    tf.keras.layers.Conv2D(128, (2,2), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    # tf.keras.layers.Conv2D(256, (2,2), activation='relu'),
    # tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(2, activation='sigmoid')

])
model.summary()

from tensorflow.keras.optimizers import RMSprop
model.compile(optimizer=RMSprop(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics = ['accuracy'])

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator( rescale = 1.0/255. ,
                                   rotation_range=20,
      width_shift_range=0.2,
      height_shift_range=0.3,
      shear_range=0.3,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')
test_datagen  = ImageDataGenerator( rescale = 1.0/255. )

train_generator = train_datagen.flow_from_directory(train_dir,
                                                    batch_size=batch_size,
                                                    class_mode='categorical',
                                                    target_size=IMAGE_SIZE )

validation_generator =  test_datagen.flow_from_directory(validation_dir,
                                                         batch_size=batch_size,
                                                         class_mode  = 'categorical',
                                                         target_size = IMAGE_SIZE)

from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler
earlystop = EarlyStopping(patience=7,restore_best_weights=True)

history = model.fit(
            train_generator,
            epochs=70,
            validation_data=validation_generator,
            verbose=2,
            callbacks=[earlystop]
            )

model.save('../content/model/my_model90.h5')  # The file needs to end with the .keras extension

import tensorflow.keras as keras
model = keras.models.load_model(model_dir+'/my_model.h5')

model.predict()

import numpy as np

from tensorflow.keras.utils import load_img, img_to_array

path = '/content/PapPla/plastic602.jpg'
img=load_img(path, target_size=(150, 150))

x=img_to_array(img)
x /= 255
x=np.expand_dims(x, axis=0)
images = np.vstack([x])

classes = model.predict(images, batch_size=10)
np.set_printoptions(suppress = True)
  # print(classes[0])
  # print(np.argmax(classes[0]))
print("It is", classes)

import numpy as np

from tensorflow.keras.utils import load_img, img_to_array

path = '/content/PapPla/cardboard10.jpg'
img=load_img(path, target_size=(150, 150))

x=img_to_array(img)
x /= 255
x=np.expand_dims(x, axis=0)
images = np.vstack([x])

classes = model.predict(images, batch_size=10)
np.set_printoptions(suppress = True)
print("It is", classes)


def result(img_path):
    img=load_img(img_path, target_size=(150, 150))

    x=img_to_array(img)
    x /= 255
    x=np.expand_dims(x, axis=0)
    images = np.vstack([x])
    classes = model.predict(images, batch_size=10)
    np.set_printoptions(suppress = True)
    print("It is", classes)


labels = ['paper', 'plastic']

result('paper.jpg')



import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()


plt.show()

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.legend(loc=0)
plt.figure()


plt.show()

def getMax(arr):
    max = 0
    for elem in arr:
        if elem > max:
            max = elem
    return max



import numpy as np

from google.colab import files
from tensorflow.keras.utils import load_img, img_to_array

uploaded=files.upload()

for fn in uploaded.keys():
  path='/content/' + fn
  img=load_img(path, target_size=(150, 150))

  x=img_to_array(img)
  x /= 255
  x=np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)
  np.set_printoptions(suppress = True)
  # print(classes[0])
  # print(np.argmax(classes[0]))

  print("It is", labels[np.argmax(classes[0])])



import tensorflow.keras as keras
model = keras.models.load_model('/content/UnSortedWaste/model/my_model.keras')

labels.sort()
print(labels)